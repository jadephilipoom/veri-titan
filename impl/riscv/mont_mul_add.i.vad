include "../../arch/riscv/decls.i.vad"
include "mul32.i.vad"
include "sub_mod.i.vad"

#verbatim
include "../../arch/riscv/decls.i.dfy"
include "../../impl/riscv/mul32.i.dfy"
include "../../impl/riscv/sub_mod.i.dfy"
include "../../../impl/riscv/mont_mul_add_lemmas.i.dfy"

module mont_mul_add {

import opened bv_ops

import opened rv_machine
import opened rv_decls
import opened rv_vale

import opened mul32
import opened sub_mod
import opened mont_mul_add_lemmas

#endverbatim

function uint64_view_zero() : uint64_view_t extern;
    
function mont_mul_add_loop_inv(
    A: uint64_view_t,
    B: uint64_view_t,
    A_prev: uint64_view_t,
    B_prev: uint64_view_t,
    n: seq(uint32),
    b: seq(uint32),
    c: seq(uint32),
    a: uint32,
    d0: uint32,
    i: nat) : bool extern;

// /**
//  * Montgomery c[] += a * b[] / R % mod
//  */
// static void mont_mul_add(const uint32_t d0inv, const uint32_t *n,
//        uint32_t *c,
//        const uint32_t a,
//        const uint32_t *b)
// {
//   uint64_t A = mula32(a, b[0], c[0]);
//   uint32_t d0 = (uint32_t)A * d0inv;
//   uint64_t B = mula32(d0, n[0], (uint32_t)A);
//   uint32_t i;
//   for (i = 1; i < RSANUMWORDS; ++i) {
//     A = mulaa32(a, b[i], c[i], A >> 32);
//     B = mulaa32(d0, n[i], (uint32_t)A, B >> 32);
//     c[i - 1] = (uint32_t)B;
//   }
//   A = (A >> 32) + (B >> 32);
//   c[i - 1] = (uint32_t)A;
//   if (A >> 32)
//     sub_mod(n, c);
// }
    
procedure mont_mul_add_loop(
    ghost A: uint64_view_t,
    ghost B: uint64_view_t,
    ghost A_prev: uint64_view_t,
    ghost B_prev: uint64_view_t,
    ghost iter_n: iter_t, ghost iter_b: iter_t, ghost iter_c: iter_t,
    ghost a: uint32, ghost d0: uint32, ghost i: nat)
    returns (ghost iter_c' : iter_t, ghost A' : uint64_view_t, ghost B' : uint64_view_t)
    lets s0 @= x16; s1 @= x17; s2 @= x18; s3 @= x19; s4 @= x20; s5 @= x21; s7 @= x23; s8 @= x24;
         a0 @= x10; a1 @= x11; a2 @= x12; a3 @= x13;
    modifies s0; s1; s2; s3; s4; s5; s7; s8; a0; a1; a2; a3;
             x14; x15; mem;

    // ** registers going into loop:
    //       a0 = a, a1 = b[1], a2 = c[1], a3 = A(uh)
    //       s0 = A(uh)
    //       s1 = B(uh)
    //       s2 = pointer to n[1]
    //       s3 = pointer to c[0]
    //       s4 = pointer to b[1]
    //       s5 = d0;
    //       s8 = pointer to end of n

    requires iter_n.index == 1;
    requires seq_len(iter_n.buff) == 96;
    requires iter_safe(iter_n, mem, 71196);

    requires iter_b.index == 1;
    requires seq_len(iter_b.buff) == 96;
    requires iter_safe(iter_b, mem, s4);

    requires iter_c.index == 0;
    requires seq_len(iter_c.buff) == 96;
    requires iter_safe(iter_c, mem, s3);

    requires s7 == a;
    
    requires s0 == A.uh;
    requires s1 == B.uh;
    requires A_prev.full == 0;
    requires B_prev.full == 0;
    
    requires s2 == iter_n.base_addr + 4 * iter_n.index;
    requires s3 == iter_c.base_addr + 4 * iter_c.index;
    requires s4 == iter_b.base_addr + 4 * iter_b.index;

    requires s5 == d0;
    requires s8 == 71576;

    requires i == 0;
    requires mont_mul_add_loop_inv(A, B, A_prev, B_prev, iter_n.buff, iter_b.buff, iter_c.buff, a, d0, i);

    ensures mont_mul_add_loop_inv(A, B, A_prev, B_prev, iter_n.buff, iter_b.buff, iter_c.buff, a, d0, i);

    ensures s3 == iter_c'.base_addr + 4 * 95;
    ensures iter_c'.index == 95;
    ensures seq_len(iter_c'.buff) == 96;
    ensures iter_safe(iter_c', mem, s3);

    ensures s0 == A'.uh;
    ensures a1 == B'.uh;
{

   ghost var A := A;
   ghost var B := B;
   ghost var A_prev := A_prev;
   ghost var B_prev := B_prev;
    
   ghost var iter_n := iter_n;
   ghost var iter_b := iter_b;
   ghost var iter_c := iter_c;
    
   ghost var i:nat := 0;
    
   while (s2 != s8)
       invariant 0 <= i < 96;

       invariant s2 == 71192 + 4 * (i+1);
       invariant s8 == 71576;

       invariant s5 == d0;
       invariant s7 == a;
    
       invariant s0 == A.uh;
       invariant s1 == B.uh;

       invariant iter_n.index == iter_b.index;
       invariant iter_n.index == i+1;
       invariant iter_c.index == i;

       invariant s2 == iter_n.base_addr + 4 * iter_n.index;
       invariant s3 == iter_c.base_addr + 4 * iter_c.index;
       invariant s4 == iter_b.base_addr + 4 * iter_b.index;

       invariant seq_len(iter_n.buff) == 96;
       invariant iter_inv(iter_n, mem, s2);
    
       invariant seq_len(iter_b.buff) == 96;
       invariant iter_inv(iter_b, mem, s4);

       invariant seq_len(iter_c.buff) == 96;
       invariant iter_safe(iter_c, mem, s3);

       invariant mont_mul_add_loop_inv(A, B, A_prev, B_prev, iter_n.buff, iter_b.buff, iter_c.buff, a, d0, i);
       invariant (i == 95 ==> a1 == B.uh);

       decreases s8 - s2;
{ 
        A_prev := A;
        B_prev := B;

        // a2 <- c[i+1]
        lw_iter(a2, s3, 4, lw_next_iter(iter_c));
        assert a2 == iter_c.buff[i+1];
        assert iter_c.index == i;
        
        // a1 <- b[i+1]
        lw_iter(a1, s4, 0, iter_b);
        assert a1 == iter_b.buff[i+1];

        // a3 <- A(uh)
        mv(a3, s0);

        // a0 <- a
        mv(a0, s7);

        assert a3 == A_prev.uh;

        // a0(lh), a1(uh) = A == a * b[i+1] + c[i+1] + A_prev(uh)
        A := mulaa32();
        assert a0 == A.lh;
        assert a1 == A.uh;
        assert A.full == a * iter_b.buff[i+1] + iter_c.buff[i+1] + A_prev.uh;
    
        // s0 <- A(uh)
        mv(s0, a1);
        assert s0 == A.uh;

        // a1 <- n[i+1]
        lw_iter(a1, s2, 0, iter_n);
        assert a1 == iter_n.buff[i+1];

        // a2 <- A(lh)
        mv(a2, a0);

        // a3 <- B(uh)
        mv(a3, s1);

        // a0 <- d0
        mv(a0, s5);
    
        assert a0 == d0;
        assert a2 == A.lh;
        assert a3 == B.uh;

        // a0(lh), a1(uh) = B == d0 * n[i+1] + A(lh) + B(uh)
        B := mulaa32();
        assert a0 == B.lh;
        assert a1 == B.uh;
        assert B.full == d0 * iter_n.buff[i+1] + A.lh + B_prev.uh;

        // c[i-1] <- B(lh) -- store to c
        sw_iter(a0, s3, 0, iter_c);
        assert iter_c.buff[i] == B.lh;
    
        // s2 <- n[i+1] -- increment pointer to n
        addi(s2, s2, 4);
        iter_n := lw_next_iter(iter_n);

        // s1 <- B(uh)
        mv(s1, a1);
        assert s1 == B.uh;
        assert a1 == B.uh;

        // s4 <- b[i+1] -- increment pointer to b
        addi(s4, s4, 4);
        iter_b := lw_next_iter(iter_b);
        
        // s3 <- c[i] -- increment pointer to c
        addi(s3, s3, 4);
        iter_c := lw_next_iter(iter_c);
        
        i := i + 1;
        assert mont_mul_add_loop_inv(A, B, A_prev, B_prev, iter_n.buff, iter_b.buff, iter_c.buff, a, d0, i);
        assert a1 == B.uh;
    }
    A' := A;
    B' := B;

    assert i == 95;
    assert s3 == iter_c.base_addr + 4 * 95;
    
    assert s0 == A'.uh;
    assert a1 == B'.uh;
    
    iter_c' := iter_c;
}
    
procedure mont_mul_add(ghost d0inv: uint32, ghost iter_stack: iter_t, ghost iter_b: iter_t, ghost iter_c: iter_t, ghost iter_n: iter_t)
    returns (ghost iter_c' : iter_t)
    lets sp @= x2; // stack pointer
         s0 @= x16; s1 @= x17;
         s2 @= x18; s3 @= x19; s4 @= x20; s5 @= x21; s6 @= x22;
         s7 @= x23; s8 @= x24; // saved registers
         a0 @= x10; a1 @= x11; a2 @= x12; a3 @= x13; // fn args and return values
         ra @= x1; //return addr
    requires sp > 48;
    requires iter_safe(iter_stack, mem, sp-48);
    requires seq_len(iter_stack.buff) == 12;
    requires iter_stack.index == 0;

    requires iter_safe(iter_n, mem, 71192);
    requires seq_len(iter_n.buff) == 96;
    requires iter_n.index == 0;

    requires iter_safe(iter_b, mem, a3);
    requires seq_len(iter_b.buff) == 96;
    requires iter_b.index == 0;

    requires iter_safe(iter_c, mem, a1);
    requires seq_len(iter_c.buff) == 96;
    requires iter_c.index == 0;

    modifies sp; s0; s1; s2; s3; s4; s5; s6; s7; s8; a0; a1; a2; a3;
             x14; x15;
             ra; mem;
    ensures
      ra == old(ra);
      s0 == old(s0);
      s1 == old(s1);
      s2 == old(s2);
      s3 == old(s3);
      s4 == old(s4);
      s5 == old(s5);
      s6 == old(s6);
      s7 == old(s7);
      s8 == old(s8);
      // sp == old(sp); // causes timeout :(
  {
    
    ghost var iter_n := iter_n;
    ghost var iter_b := iter_b;
    ghost var iter_c := iter_c;
    
    ghost var d0inv := a0;
    ghost var a := a2;
    
    // starting values
    // a0 = d0inv
    // a1 = pointer to c
    // a2 = a
    // a3 = pointer to b

    // sp to start of stack
    addi(sp, sp, (-48));

    // store s6 to sp[4]
    sw_stack(s6, 16, 4);

    // s6 <- a1
    mv(s6, a1);
    assert iter_safe(iter_c, mem, s6);

    // store s7 to sp[3]
    sw_stack(s7, 12, 3);

    // a1 <- a3 = b[0]
    lw_iter(a1, a3, 0, iter_b);
    assert a1 == iter_b.buff[0];

    //s7 <- a2 = "a"
    mv(s7, a2);

    // a2 <- original a1 = c[0]
    lw_iter(a2, s6, 0, iter_c);
    assert a2 == iter_c.buff[0];

    // store s5 to sp[5]
    sw_stack(s5, 20, 5);

    // s5 <- a0 = d0inv
    mv(s5, a0);

    // a0 <- original a2 == "a"
    mv(a0, s7);

    sw_stack(ra, 44, 11);
    sw_stack(s0, 40, 10);
    sw_stack(s1, 36, 9);
    sw_stack(s2, 32, 8);
    sw_stack(s3, 28, 7);
    sw_stack(s4, 24, 6);
    sw_stack(s8, 8, 2);
    
    let old_stack := mem[sp];

    // s4 <- pointer to b
    mv(s4, a3);
    
    // ** before mula32 call:
    //      sp[2..10] = s8, s7, ..., s10
    //      sp[11] = ra

    //      a0 = a, a1 = b[0], a2 = c[0]
    //      s6 = pointer to (beginning of) c
    //      s5 = d0inv
    //      s4 = pointer to b
    //      s7 = a

    // a0(lh), a1(uh) = A == a * b[0] + c[0]
    assert a1 == iter_b.buff[0];
    assert a2 == iter_c.buff[0];
    assert a0 == a;
    
    let A := mula32();
    assert a0 == A.lh;
    assert a1 == A.uh;
    assert A.full == a * iter_b.buff[0] + iter_c.buff[0];
    
    // s5 <- A(lh) * d0inv
    mul(s5, a0, s5);
    assert s5 == uint32_mul(A.lh, d0inv);
    ghost var d0 := s5;
    
    // s8 <- pointer to n (71192)
    lui(s8, 0x11);
    assume 0x11000 == s8;
    addi(s8, s8, 1560);
    assert s8 == 71192;

    // s0 <- A(uh)
    mv(s0, a1);
    // a1 <- n[0]
    lw_iter(a1, s8, 0, iter_n);

    // a2 <- A(lh)
    mv(a2, a0);

    assert a1 == iter_n.buff[0];
    assert a2 == A.lh;
    
    // s2 <- pointer to n[1]
    addi(s2, s8, 4);
    iter_n := lw_next_iter(iter_n);

    // s4 <- pointer to b[1]
    addi(s4, s4, 4);
    iter_b := lw_next_iter(iter_b);
    
    // s3 <- pointer to c
    mv(s3, s6);
    assert iter_safe(iter_c, mem, s3);

    // s8 <- pointer to end of n
    addi(s8, s8, 384);
    
    // a0 = d0
    mv(a0, s5);
    assert a0 == d0;
    
    // a0(lh), a1(uh) = B == d0 * n[0] + A(lh)
    let B := mula32();
    assert a0 == B.lh;
    assert a1 == B.uh;
    assert B.full == d0 * iter_n.buff[0] + A.lh;

    // s1 <- B(uh)
    mv(s1, a1);

    assert s2 == 71196;
    assert s3 == iter_c.base_addr;
    assert s4 == iter_b.base_addr + 4;
    assert s5 == d0;

    ghost var i:nat := 0;
    ghost var zero64 := uint64_view_zero();

    assert mont_mul_add_loop_inv(A, B, zero64, zero64, iter_n.buff, iter_b.buff, iter_c.buff, a, d0, i);

    ghost var A' : uint64_view_t;
    ghost var B' : uint64_view_t;
    iter_c', A', B' := mont_mul_add_loop(A, B, zero64, zero64, iter_n, iter_b, iter_c, a, d0, i);

    // ** end of loop:
    //      c[0..i-1] computed
    //      s1 = B(uh)
    //      s2 = end of n
    //      s3 = last spot of c
    //      s4 = end of b

    // s0 <- lower half of A(uh) + B(uh) == A'
    add(s0, s0, a1);
    assert s0 == uint32_add(A'.uh, B'.uh);
    assert a1 == B'.uh;
    let A_cmp := s0;

    // TODO: need to show that iter_c.base_addr == iter_c'.base_addr
    assume iter_c.base_addr == iter_c'.base_addr;
    sw_iter(s0, s6, 380, iter_c');
    
    // if stmt true when A(uh) > 0, causing lh(A(uh + B(uh) to overflow
    // lh(A(uh + B(uh)) < B(uh) <-- happens when A'(uh) is non-empty
    // bltu    s0, a1, 1026a <mont_mul_add.constprop.0+0x9a>

    // TODO: show that mem[sp] isn't changed from mont_mul_add_loop call
    assume mem?[sp];
    assume old_stack == mem[sp];
    assume seq_len(mem[sp]) == 12;
    
    if (s0 < a1) {
        // A'(lh) > case:
        // assert A_cmp > 0;

        lw_stack(s0, 40, 10);
        lw_stack(ra, 44, 11);
        lw_stack(s1, 36, 9);
        lw_stack(s2, 32, 8);
        lw_stack(s3, 28, 7);
        lw_stack(s4, 24, 6);
        lw_stack(s5, 20, 5);
        lw_stack(s7, 12, 3);
        lw_stack(s8, 8, 2);
    
        // a0 <- pointer to start of c
        mv(a0, s6);

        lw_stack(s6, 16, 4);

        // recover initial sp
        addi(sp, sp, 48);
    
        // TODO: meet preconditions for sub_mod
        // reset iter_n.index
        // reset iter_c'.index
        // iter_c.base_addr != iter_c'.base_addr

        // a0 = sub_mod(n, c) == 1 if c >= n else 0
        // ghost var A_sm : int64_view_t;
        // iter_c', A_sm := sub_mod(iter_n, iter_c');

    } else {
        // A'(lh) == 0 case:
        // assert A_cmp == 0;
    
        lw_stack(ra, 44, 11);
        lw_stack(s0, 40, 10);
        lw_stack(s1, 36, 9);
        lw_stack(s2, 32, 8);
        lw_stack(s3, 28, 7);
        lw_stack(s4, 24, 6);
        lw_stack(s5, 20, 5);
        lw_stack(s6, 16, 4);
        lw_stack(s7, 12, 3);
        lw_stack(s8, 8, 2);
        
        // recover initial sp
        addi(sp, sp, 48);
        // ret
    }
  }

#verbatim
}
#endverbatim
